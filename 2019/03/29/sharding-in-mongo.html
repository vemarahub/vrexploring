<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Sharding in Mongo | VR Exploring</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Sharding in Mongo" />
<meta name="author" content="Rajesh Nair" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Sharding is the method of data distribution in a mongo database environment where the data can be partitioned into different servers on the basis of &quot;shard keys&quot;. Documents having same shard keys will be in same shards, also with within range will also be in same shards – “range-based partitioning”. Replication with Sharding Chunks and Operation The data that key range refers to in a shard is known as “Chunk” ~ 100 MB each. Two operations with data automatically done on sharding: 1. Split – split key range into two key ranges when size of chunk is too big.select mid point to data range.Inexpensive. 2. Migrate – To maintain balance.migrate chunk from S0 to S1 .Copy and remove from S0 then update metadata to point the chunk to S1.Not inexpensive.Thus, between a pair of nodes not more than 1 migration will be undertaken.&quot;liveliness&quot; – no lock occurring of chunk. “balancer” – decides when to do migration and where. Sharding Process config servers – Small mongods .metadata of clusters are stored in this. Usually we can have 3 config servers in prod. If config server is down, the cluster will also be down. mongos – client connects to mongos to view whole cluster as single entity.No persistent state. mongod – Process for data store . Cluster Topology Cluster Setup defines how many shards initially we should have and the replication factor.For an ideal production environment: Initial Shards – 4 Repl factor – 3 Mongos processes – 4 Config servers – 3 Thus we will have :3 * 4 = 12 mongod shard servers Cardinality &amp; Monotonic Shard Keys -&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The shard key is common in queries for the collection -&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Good ‘cardinality’/granuality -&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Consider compound shardKeys -&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Is the key monotonically increasing? – eg timestamp – BSON object ID do this. Shard Key Selection Example Either _id Or compound {company:1,date:1} Process and Machine Layout Shard servers ( mongod –shardsvr) – replicas(RF = 3) Config servers ( mongod –configsvr) - 3 Mongos processes ( mongos) – ideally 4 Bulk Insert &amp; Pre-Splitting On normal cases of a bulk load for a sharded cluster with shard s1, s2,s3,s4,s5 if loading is faster in s1 than other shards, it may result in data getting loaded more to s1. Pre-Splitting before Bulk Load: mongos&gt; sh.shardCollection(&quot;myDB.pre_demo&quot;,{x:1}) mongos&gt; for(var i = 0; i &lt; 100 ; i++){ ... sh.splitAt(&quot;myDB.pre_demo&quot;,{x:1000000 * i/100}); ... } mongos&gt; db.chunks.find( { ns: /demo/ },{_id:0,lastmodEpoch:0,lastmod:0}) { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 970000 }, &quot;max&quot; : { &quot;x&quot; : 980000 }, &quot;shard&quot; : &quot;c&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 980000 }, &quot;max&quot; : { &quot;x&quot; : 990000 }, &quot;shard&quot; : &quot;c&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 990000 }, &quot;max&quot; : { &quot;x&quot; : { &quot;$maxKey&quot; : 1 } }, &quot;shard&quot; : &quot;c&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 10000 }, &quot;max&quot; : { &quot;x&quot; : 20000 }, &quot;shard&quot; : &quot;b&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 20000 }, &quot;max&quot; : { &quot;x&quot; : 30000 }, &quot;shard&quot; : &quot;d&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 30000 }, &quot;max&quot; : { &quot;x&quot; : 40000 }, &quot;shard&quot; : &quot;d&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 40000 }, &quot;max&quot; : { &quot;x&quot; : 50000 }, &quot;shard&quot; : &quot;b&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 50000 }, &quot;max&quot; : { &quot;x&quot; : 60000 }, &quot;shard&quot; : &quot;b&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 60000 }, &quot;max&quot; : { &quot;x&quot; : 70000 }, &quot;shard&quot; : &quot;d&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 70000 }, &quot;max&quot; : { &quot;x&quot; : 80000 }, &quot;shard&quot; : &quot;a&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 80000 }, &quot;max&quot; : { &quot;x&quot; : 90000 }, &quot;shard&quot; : &quot;b&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 90000 }, &quot;max&quot; : { &quot;x&quot; : 100000 }, &quot;shard&quot; : &quot;a&quot; } Shard key selection: High Cardinality(no of values), low frequency(repetitive occurrence in insert),type of change non monotonically(timestamp changes monitonically) Shard is a permanent operation ·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; You cannot unshard a collection once sharded ·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; You cannot update the shard key of a sharded collection ·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; You cannot update the values of the shard key for any document in the sharded collection e Tips &amp; Best Practices • Only shard big collections • Pick shard keys carefully • Consider pre splitting on bulk load • Be aware of monotonically increasing shard key values on inserts • Adding new shard is online but isn’t instantaneous. • Always connect to mongos ,except for some dba work – put mongos on default port • Use logical config server names. Hashed Shard Key: index for the shard key is hashed db.collection.createIndex({field:”hashed”}) chunk size – 64mb 1 MB &lt;chunk 1=&quot;&quot; gb=&quot;&quot; p=&quot;&quot;&gt;db.chunks.findOne() use config db.settings.save({_id: &quot;chunksize&quot;, value: 2}) in MB Jumbo chunks – when similar docs move into particular shard Cannot move jumbo chunks, Once marked as jumbo the balancer skips these and avoids trying to move them Balancer is located in primary of config server. Start the balancer: sh.startBalancer(timeout, interval) Stop the balancer: sh.stopBalancer(timeout, interval) Enable/disable the balancer: sh.setBalancerState(boolean) mongos does the query merging limit() and sort()are pushed to each shard by mongos then mergesorted skip() is applied against the merged set of results &lt;/chunk&gt; &lt;chunk 1=&quot;&quot; gb=&quot;&quot; p=&quot;&quot;&gt;&lt;/chunk&gt; config database keeps a table of shard chunk relationship mongos keeps a cache of this relationship.scatter gather is used for query not having shard key.Thus shard key should be used in majority of queries. db.products.find({&quot;sku&quot; : 1000000749 }).explain() – stage : single shard db.products.find( { &nbsp; &quot;name&quot; : &quot;Gods And Heroes: Rome Rising - Windows [Digital Download]&quot; } &lt;chunk 1=&quot;&quot; gb=&quot;&quot; p=&quot;&quot;&gt;&lt;/chunk&gt; ).explain() – stage : shard merge All chunk migrations use the following procedure: * The balancer process sends the moveChunk command to the source shard. * The source starts the move with an internal moveChunk command. During the migration process, operations to the chunk route to the source shard. The source shard is responsible for incoming write operations for the chunk. * The destination shard builds any indexes required by the source that do not exist on the destination. * The destination shard begins requesting documents in the chunk and starts receiving copies of the data. See also Chunk Migration and Replication. * After receiving the final document in the chunk, the destination shard starts a synchronization process to ensure that it has the changes to the migrated documents that occurred during the migration. * When fully synchronized, the source shard connects to the config database and updates the cluster metadata with the new location for the chunk. * After the source shard completes the update of the metadata, and once there are no open cursors on the chunk, the source shard deletes its copy of the documents." />
<meta property="og:description" content="Sharding is the method of data distribution in a mongo database environment where the data can be partitioned into different servers on the basis of &quot;shard keys&quot;. Documents having same shard keys will be in same shards, also with within range will also be in same shards – “range-based partitioning”. Replication with Sharding Chunks and Operation The data that key range refers to in a shard is known as “Chunk” ~ 100 MB each. Two operations with data automatically done on sharding: 1. Split – split key range into two key ranges when size of chunk is too big.select mid point to data range.Inexpensive. 2. Migrate – To maintain balance.migrate chunk from S0 to S1 .Copy and remove from S0 then update metadata to point the chunk to S1.Not inexpensive.Thus, between a pair of nodes not more than 1 migration will be undertaken.&quot;liveliness&quot; – no lock occurring of chunk. “balancer” – decides when to do migration and where. Sharding Process config servers – Small mongods .metadata of clusters are stored in this. Usually we can have 3 config servers in prod. If config server is down, the cluster will also be down. mongos – client connects to mongos to view whole cluster as single entity.No persistent state. mongod – Process for data store . Cluster Topology Cluster Setup defines how many shards initially we should have and the replication factor.For an ideal production environment: Initial Shards – 4 Repl factor – 3 Mongos processes – 4 Config servers – 3 Thus we will have :3 * 4 = 12 mongod shard servers Cardinality &amp; Monotonic Shard Keys -&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The shard key is common in queries for the collection -&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Good ‘cardinality’/granuality -&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Consider compound shardKeys -&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Is the key monotonically increasing? – eg timestamp – BSON object ID do this. Shard Key Selection Example Either _id Or compound {company:1,date:1} Process and Machine Layout Shard servers ( mongod –shardsvr) – replicas(RF = 3) Config servers ( mongod –configsvr) - 3 Mongos processes ( mongos) – ideally 4 Bulk Insert &amp; Pre-Splitting On normal cases of a bulk load for a sharded cluster with shard s1, s2,s3,s4,s5 if loading is faster in s1 than other shards, it may result in data getting loaded more to s1. Pre-Splitting before Bulk Load: mongos&gt; sh.shardCollection(&quot;myDB.pre_demo&quot;,{x:1}) mongos&gt; for(var i = 0; i &lt; 100 ; i++){ ... sh.splitAt(&quot;myDB.pre_demo&quot;,{x:1000000 * i/100}); ... } mongos&gt; db.chunks.find( { ns: /demo/ },{_id:0,lastmodEpoch:0,lastmod:0}) { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 970000 }, &quot;max&quot; : { &quot;x&quot; : 980000 }, &quot;shard&quot; : &quot;c&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 980000 }, &quot;max&quot; : { &quot;x&quot; : 990000 }, &quot;shard&quot; : &quot;c&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 990000 }, &quot;max&quot; : { &quot;x&quot; : { &quot;$maxKey&quot; : 1 } }, &quot;shard&quot; : &quot;c&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 10000 }, &quot;max&quot; : { &quot;x&quot; : 20000 }, &quot;shard&quot; : &quot;b&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 20000 }, &quot;max&quot; : { &quot;x&quot; : 30000 }, &quot;shard&quot; : &quot;d&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 30000 }, &quot;max&quot; : { &quot;x&quot; : 40000 }, &quot;shard&quot; : &quot;d&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 40000 }, &quot;max&quot; : { &quot;x&quot; : 50000 }, &quot;shard&quot; : &quot;b&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 50000 }, &quot;max&quot; : { &quot;x&quot; : 60000 }, &quot;shard&quot; : &quot;b&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 60000 }, &quot;max&quot; : { &quot;x&quot; : 70000 }, &quot;shard&quot; : &quot;d&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 70000 }, &quot;max&quot; : { &quot;x&quot; : 80000 }, &quot;shard&quot; : &quot;a&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 80000 }, &quot;max&quot; : { &quot;x&quot; : 90000 }, &quot;shard&quot; : &quot;b&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 90000 }, &quot;max&quot; : { &quot;x&quot; : 100000 }, &quot;shard&quot; : &quot;a&quot; } Shard key selection: High Cardinality(no of values), low frequency(repetitive occurrence in insert),type of change non monotonically(timestamp changes monitonically) Shard is a permanent operation ·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; You cannot unshard a collection once sharded ·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; You cannot update the shard key of a sharded collection ·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; You cannot update the values of the shard key for any document in the sharded collection e Tips &amp; Best Practices • Only shard big collections • Pick shard keys carefully • Consider pre splitting on bulk load • Be aware of monotonically increasing shard key values on inserts • Adding new shard is online but isn’t instantaneous. • Always connect to mongos ,except for some dba work – put mongos on default port • Use logical config server names. Hashed Shard Key: index for the shard key is hashed db.collection.createIndex({field:”hashed”}) chunk size – 64mb 1 MB &lt;chunk 1=&quot;&quot; gb=&quot;&quot; p=&quot;&quot;&gt;db.chunks.findOne() use config db.settings.save({_id: &quot;chunksize&quot;, value: 2}) in MB Jumbo chunks – when similar docs move into particular shard Cannot move jumbo chunks, Once marked as jumbo the balancer skips these and avoids trying to move them Balancer is located in primary of config server. Start the balancer: sh.startBalancer(timeout, interval) Stop the balancer: sh.stopBalancer(timeout, interval) Enable/disable the balancer: sh.setBalancerState(boolean) mongos does the query merging limit() and sort()are pushed to each shard by mongos then mergesorted skip() is applied against the merged set of results &lt;/chunk&gt; &lt;chunk 1=&quot;&quot; gb=&quot;&quot; p=&quot;&quot;&gt;&lt;/chunk&gt; config database keeps a table of shard chunk relationship mongos keeps a cache of this relationship.scatter gather is used for query not having shard key.Thus shard key should be used in majority of queries. db.products.find({&quot;sku&quot; : 1000000749 }).explain() – stage : single shard db.products.find( { &nbsp; &quot;name&quot; : &quot;Gods And Heroes: Rome Rising - Windows [Digital Download]&quot; } &lt;chunk 1=&quot;&quot; gb=&quot;&quot; p=&quot;&quot;&gt;&lt;/chunk&gt; ).explain() – stage : shard merge All chunk migrations use the following procedure: * The balancer process sends the moveChunk command to the source shard. * The source starts the move with an internal moveChunk command. During the migration process, operations to the chunk route to the source shard. The source shard is responsible for incoming write operations for the chunk. * The destination shard builds any indexes required by the source that do not exist on the destination. * The destination shard begins requesting documents in the chunk and starts receiving copies of the data. See also Chunk Migration and Replication. * After receiving the final document in the chunk, the destination shard starts a synchronization process to ensure that it has the changes to the migrated documents that occurred during the migration. * When fully synchronized, the source shard connects to the config database and updates the cluster metadata with the new location for the chunk. * After the source shard completes the update of the metadata, and once there are no open cursors on the chunk, the source shard deletes its copy of the documents." />
<link rel="canonical" href="https://vemarahub.github.io/vrexploring/2019/03/29/sharding-in-mongo.html" />
<meta property="og:url" content="https://vemarahub.github.io/vrexploring/2019/03/29/sharding-in-mongo.html" />
<meta property="og:site_name" content="VR Exploring" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-03-29T08:48:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Sharding in Mongo" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Rajesh Nair"},"dateModified":"2019-03-29T08:48:00+00:00","datePublished":"2019-03-29T08:48:00+00:00","description":"Sharding is the method of data distribution in a mongo database environment where the data can be partitioned into different servers on the basis of &quot;shard keys&quot;. Documents having same shard keys will be in same shards, also with within range will also be in same shards – “range-based partitioning”. Replication with Sharding Chunks and Operation The data that key range refers to in a shard is known as “Chunk” ~ 100 MB each. Two operations with data automatically done on sharding: 1. Split – split key range into two key ranges when size of chunk is too big.select mid point to data range.Inexpensive. 2. Migrate – To maintain balance.migrate chunk from S0 to S1 .Copy and remove from S0 then update metadata to point the chunk to S1.Not inexpensive.Thus, between a pair of nodes not more than 1 migration will be undertaken.&quot;liveliness&quot; – no lock occurring of chunk. “balancer” – decides when to do migration and where. Sharding Process config servers – Small mongods .metadata of clusters are stored in this. Usually we can have 3 config servers in prod. If config server is down, the cluster will also be down. mongos – client connects to mongos to view whole cluster as single entity.No persistent state. mongod – Process for data store . Cluster Topology Cluster Setup defines how many shards initially we should have and the replication factor.For an ideal production environment: Initial Shards – 4 Repl factor – 3 Mongos processes – 4 Config servers – 3 Thus we will have :3 * 4 = 12 mongod shard servers Cardinality &amp; Monotonic Shard Keys -&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The shard key is common in queries for the collection -&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Good ‘cardinality’/granuality -&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Consider compound shardKeys -&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Is the key monotonically increasing? – eg timestamp – BSON object ID do this. Shard Key Selection Example Either _id Or compound {company:1,date:1} Process and Machine Layout Shard servers ( mongod –shardsvr) – replicas(RF = 3) Config servers ( mongod –configsvr) - 3 Mongos processes ( mongos) – ideally 4 Bulk Insert &amp; Pre-Splitting On normal cases of a bulk load for a sharded cluster with shard s1, s2,s3,s4,s5 if loading is faster in s1 than other shards, it may result in data getting loaded more to s1. Pre-Splitting before Bulk Load: mongos&gt; sh.shardCollection(&quot;myDB.pre_demo&quot;,{x:1}) mongos&gt; for(var i = 0; i &lt; 100 ; i++){ ... sh.splitAt(&quot;myDB.pre_demo&quot;,{x:1000000 * i/100}); ... } mongos&gt; db.chunks.find( { ns: /demo/ },{_id:0,lastmodEpoch:0,lastmod:0}) { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 970000 }, &quot;max&quot; : { &quot;x&quot; : 980000 }, &quot;shard&quot; : &quot;c&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 980000 }, &quot;max&quot; : { &quot;x&quot; : 990000 }, &quot;shard&quot; : &quot;c&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 990000 }, &quot;max&quot; : { &quot;x&quot; : { &quot;$maxKey&quot; : 1 } }, &quot;shard&quot; : &quot;c&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 10000 }, &quot;max&quot; : { &quot;x&quot; : 20000 }, &quot;shard&quot; : &quot;b&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 20000 }, &quot;max&quot; : { &quot;x&quot; : 30000 }, &quot;shard&quot; : &quot;d&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 30000 }, &quot;max&quot; : { &quot;x&quot; : 40000 }, &quot;shard&quot; : &quot;d&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 40000 }, &quot;max&quot; : { &quot;x&quot; : 50000 }, &quot;shard&quot; : &quot;b&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 50000 }, &quot;max&quot; : { &quot;x&quot; : 60000 }, &quot;shard&quot; : &quot;b&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 60000 }, &quot;max&quot; : { &quot;x&quot; : 70000 }, &quot;shard&quot; : &quot;d&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 70000 }, &quot;max&quot; : { &quot;x&quot; : 80000 }, &quot;shard&quot; : &quot;a&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 80000 }, &quot;max&quot; : { &quot;x&quot; : 90000 }, &quot;shard&quot; : &quot;b&quot; } { &quot;ns&quot; : &quot;myDB.pre_demo&quot;, &quot;min&quot; : { &quot;x&quot; : 90000 }, &quot;max&quot; : { &quot;x&quot; : 100000 }, &quot;shard&quot; : &quot;a&quot; } Shard key selection: High Cardinality(no of values), low frequency(repetitive occurrence in insert),type of change non monotonically(timestamp changes monitonically) Shard is a permanent operation ·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; You cannot unshard a collection once sharded ·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; You cannot update the shard key of a sharded collection ·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; You cannot update the values of the shard key for any document in the sharded collection e Tips &amp; Best Practices • Only shard big collections • Pick shard keys carefully • Consider pre splitting on bulk load • Be aware of monotonically increasing shard key values on inserts • Adding new shard is online but isn’t instantaneous. • Always connect to mongos ,except for some dba work – put mongos on default port • Use logical config server names. Hashed Shard Key: index for the shard key is hashed db.collection.createIndex({field:”hashed”}) chunk size – 64mb 1 MB &lt;chunk 1=&quot;&quot; gb=&quot;&quot; p=&quot;&quot;&gt;db.chunks.findOne() use config db.settings.save({_id: &quot;chunksize&quot;, value: 2}) in MB Jumbo chunks – when similar docs move into particular shard Cannot move jumbo chunks, Once marked as jumbo the balancer skips these and avoids trying to move them Balancer is located in primary of config server. Start the balancer: sh.startBalancer(timeout, interval) Stop the balancer: sh.stopBalancer(timeout, interval) Enable/disable the balancer: sh.setBalancerState(boolean) mongos does the query merging limit() and sort()are pushed to each shard by mongos then mergesorted skip() is applied against the merged set of results &lt;/chunk&gt; &lt;chunk 1=&quot;&quot; gb=&quot;&quot; p=&quot;&quot;&gt;&lt;/chunk&gt; config database keeps a table of shard chunk relationship mongos keeps a cache of this relationship.scatter gather is used for query not having shard key.Thus shard key should be used in majority of queries. db.products.find({&quot;sku&quot; : 1000000749 }).explain() – stage : single shard db.products.find( { &nbsp; &quot;name&quot; : &quot;Gods And Heroes: Rome Rising - Windows [Digital Download]&quot; } &lt;chunk 1=&quot;&quot; gb=&quot;&quot; p=&quot;&quot;&gt;&lt;/chunk&gt; ).explain() – stage : shard merge All chunk migrations use the following procedure: * The balancer process sends the moveChunk command to the source shard. * The source starts the move with an internal moveChunk command. During the migration process, operations to the chunk route to the source shard. The source shard is responsible for incoming write operations for the chunk. * The destination shard builds any indexes required by the source that do not exist on the destination. * The destination shard begins requesting documents in the chunk and starts receiving copies of the data. See also Chunk Migration and Replication. * After receiving the final document in the chunk, the destination shard starts a synchronization process to ensure that it has the changes to the migrated documents that occurred during the migration. * When fully synchronized, the source shard connects to the config database and updates the cluster metadata with the new location for the chunk. * After the source shard completes the update of the metadata, and once there are no open cursors on the chunk, the source shard deletes its copy of the documents.","headline":"Sharding in Mongo","mainEntityOfPage":{"@type":"WebPage","@id":"https://vemarahub.github.io/vrexploring/2019/03/29/sharding-in-mongo.html"},"url":"https://vemarahub.github.io/vrexploring/2019/03/29/sharding-in-mongo.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/vrexploring/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://vemarahub.github.io/vrexploring/feed.xml" title="VR Exploring" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/vrexploring/">VR Exploring</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/vrexploring/about/">About</a><a class="page-link" href="/vrexploring/">Home</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Sharding in Mongo</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2019-03-29T08:48:00+00:00" itemprop="datePublished">Mar 29, 2019
      </time>• <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span class="p-author h-card" itemprop="name">Rajesh Nair</span></span></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <div dir="ltr" style="text-align: left;" trbidi="on">
Sharding is the method of data distribution in a mongo database environment where the data can be partitioned into different servers on the basis of "shard keys".<br />
Documents having same shard keys will be in same shards, also with within range will also be in same shards – “range-based partitioning”.<br />
<div class="separator" style="clear: both; text-align: center;">
<a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgPU7-KmtKEymzXse0jMdOZZWYGfTYLDoUoDiQW6j9E86aKLtzMTJDhIoBpS4OVVD4YZUCex-q6tCTVy_Isnvj_8N4QdDMMaJGLHwT2BUVC2cBLhFJ-5YgnGMjwcuQFr6zbY7pDA8am79k/s1600/abc.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="547" data-original-width="973" height="358" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgPU7-KmtKEymzXse0jMdOZZWYGfTYLDoUoDiQW6j9E86aKLtzMTJDhIoBpS4OVVD4YZUCex-q6tCTVy_Isnvj_8N4QdDMMaJGLHwT2BUVC2cBLhFJ-5YgnGMjwcuQFr6zbY7pDA8am79k/s640/abc.png" width="640" /></a></div>
<br />
<h3 style="text-align: left;">
Replication with Sharding</h3>
<div class="separator" style="clear: both; text-align: center;">
<a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEho6UU_EdYKcg4u_kjzsDL6bs2sYkeRPccjn-U49_iQaelpbZ9DDwIyPbB6uqEyt71RYm2PbCjQDOzF0ZsqE_4THOfraBvgCvf70uBYxq5X_Hx6iTxpGI4eC0gbUGRlBE7eoYJ4yHEjHGw/s1600/aas.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="805" data-original-width="1432" height="358" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEho6UU_EdYKcg4u_kjzsDL6bs2sYkeRPccjn-U49_iQaelpbZ9DDwIyPbB6uqEyt71RYm2PbCjQDOzF0ZsqE_4THOfraBvgCvf70uBYxq5X_Hx6iTxpGI4eC0gbUGRlBE7eoYJ4yHEjHGw/s640/aas.png" width="640" /></a></div>
<div>
<br /></div>
<div>
<br /></div>
<h3 style="text-align: left;">
Chunks and Operation</h3>
<div>
<div>
The data that key range refers to in a shard is known as “Chunk” ~ 100 MB each.</div>
<div>
Two operations with data automatically done on sharding:</div>
<div>
1.<span style="white-space: pre;"> </span>Split – split key range into two key ranges when size of chunk is too big.select mid point to data range.Inexpensive.</div>
<div>
<br /></div>
<div>
2.<span style="white-space: pre;"> </span>Migrate – To maintain balance.migrate chunk from S0 to S1 .Copy and remove from S0 then update metadata to point the chunk to S1.Not inexpensive.Thus, between a pair of nodes not more than 1 migration will be undertaken."liveliness" – no lock occurring of chunk.</div>
<div>
<br /></div>
<div>
“balancer” – decides when to do migration and where.</div>
</div>
<div>
<br /></div>
<h3 style="text-align: left;">
Sharding Process</h3>
<div>
<div>
<b>config servers</b> – Small mongods .metadata of clusters are stored in this.</div>
<div>
Usually we can have 3 config servers in prod. If config server is down, the cluster will also be down.</div>
<div>
<b>mongos</b> – client connects to mongos to view whole cluster as single entity.No persistent state.</div>
<div>
<b>mongod </b>– Process for data store .</div>
</div>
<div>
<br /></div>
<div class="separator" style="clear: both; text-align: center;">
<a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh3imDege5h9z6gUo55h7koFYzTQqFzW54A7oeZcuHNb1rU7VqFFBZNKKou1aCh5axmfUarNHWywDfNLGEeje7GfrVKpSarARzxS6fScDMV2RBPqWDNuFaUEW_zLngk2L-kTU5CxFaHmVw/s1600/aq.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="750" data-original-width="1332" height="360" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh3imDege5h9z6gUo55h7koFYzTQqFzW54A7oeZcuHNb1rU7VqFFBZNKKou1aCh5axmfUarNHWywDfNLGEeje7GfrVKpSarARzxS6fScDMV2RBPqWDNuFaUEW_zLngk2L-kTU5CxFaHmVw/s640/aq.png" width="640" /></a></div>
<div>
<br /></div>
<h3 style="text-align: left;">
Cluster Topology</h3>
<div>
<div class="MsoNormal">
Cluster Setup defines how many shards initially we should have and the replication
factor.For an ideal production environment:<o:p></o:p></div>
<div class="MsoNormal">
Initial Shards – 4<o:p></o:p></div>
<div class="MsoNormal">
Repl factor – 3<o:p></o:p></div>
<div class="MsoNormal">
Mongos processes – 4<o:p></o:p></div>
<div class="MsoNormal">
Config servers – 3<o:p></o:p></div>
<div class="MsoNormal">
<br /></div>
<div class="MsoNormal">
Thus we will have :3 * 4 = 12 mongod shard servers <o:p></o:p><br />
<br />
<br />
<h2>
Cardinality &amp; Monotonic Shard Keys<o:p></o:p></h2>
<div class="MsoNormal">
<br /></div>
<div class="MsoListParagraphCxSpFirst" style="mso-list: l0 level1 lfo1; text-indent: -.25in;">
<!--[if !supportLists]--><span style="mso-ascii-font-family: Calibri; mso-bidi-font-family: Calibri; mso-fareast-font-family: Calibri; mso-hansi-font-family: Calibri;"><span style="mso-list: Ignore;">-<span style="font: 7.0pt &quot;Times New Roman&quot;;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><!--[endif]-->The shard key is common in queries for the
collection<o:p></o:p></div>
<div class="MsoListParagraphCxSpMiddle" style="mso-list: l0 level1 lfo1; text-indent: -.25in;">
<!--[if !supportLists]--><span style="mso-ascii-font-family: Calibri; mso-bidi-font-family: Calibri; mso-fareast-font-family: Calibri; mso-hansi-font-family: Calibri;"><span style="mso-list: Ignore;">-<span style="font: 7.0pt &quot;Times New Roman&quot;;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><!--[endif]-->Good ‘cardinality’/granuality<o:p></o:p></div>
<div class="MsoListParagraphCxSpMiddle" style="mso-list: l0 level1 lfo1; text-indent: -.25in;">
<!--[if !supportLists]--><span style="mso-ascii-font-family: Calibri; mso-bidi-font-family: Calibri; mso-fareast-font-family: Calibri; mso-hansi-font-family: Calibri;"><span style="mso-list: Ignore;">-<span style="font: 7.0pt &quot;Times New Roman&quot;;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><!--[endif]-->Consider compound shardKeys<o:p></o:p></div>
<div class="MsoListParagraphCxSpLast" style="mso-list: l0 level1 lfo1; text-indent: -.25in;">
<!--[if !supportLists]--><span style="mso-ascii-font-family: Calibri; mso-bidi-font-family: Calibri; mso-fareast-font-family: Calibri; mso-hansi-font-family: Calibri;"><span style="mso-list: Ignore;">-<span style="font: 7.0pt &quot;Times New Roman&quot;;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><!--[endif]-->Is the key monotonically increasing? – eg
timestamp – BSON object ID do this.<o:p></o:p></div>
<div class="MsoNormal">
<br /></div>
<div class="MsoNormal">
<b style="mso-bidi-font-weight: normal;">Shard Key Selection
Example<o:p></o:p></b></div>
<div class="MsoNormal">
Either _id<o:p></o:p></div>
<div class="MsoNormal">
Or compound {company:1,date:1}<o:p></o:p></div>
<br />
<h3 style="text-align: left;">
Process and Machine Layout</h3>
<br />
<div class="MsoNormal">
Shard servers ( mongod –shardsvr) – replicas(RF = 3)<o:p></o:p></div>
<div class="MsoNormal">
Config servers ( mongod –configsvr) - 3<o:p></o:p></div>
<div class="MsoNormal">
Mongos processes ( mongos) – ideally 4<o:p></o:p></div>
<br />
<br />
<div class="separator" style="clear: both; text-align: center;">
<a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEink0tFbTACNMGzOHM34XFGp-XvMu7xxUZbPNQ9i1J5k-ISxh2ZuwVELlwJcYoeJABmwgoLblBcjy5VSwKtBzSLRafWBQnQX70jFM2B5Z9PboQuLQsZqgQlHz2IUA0WYWGnOeQQN0cupH8/s1600/aqw.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="900" data-original-width="1600" height="360" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEink0tFbTACNMGzOHM34XFGp-XvMu7xxUZbPNQ9i1J5k-ISxh2ZuwVELlwJcYoeJABmwgoLblBcjy5VSwKtBzSLRafWBQnQX70jFM2B5Z9PboQuLQsZqgQlHz2IUA0WYWGnOeQQN0cupH8/s640/aqw.png" width="640" /></a></div>
<h3 style="text-align: left;">
</h3>
<h3 style="text-align: left;">
<span style="font-size: 18.72px;">Bulk Insert &amp; Pre-Splitting</span></h3>
<div class="MsoNormal">
On normal cases of a bulk load for a sharded cluster with shard s1, s2,s3,s4,s5 if loading is faster in s1 than other shards, it may result in data getting loaded more to s1.<o:p></o:p></div>
<div class="MsoNormal">
<br /></div>
<div class="MsoNormal">
<b>Pre-Splitting before
Bulk Load:<o:p></o:p></b></div>
<div class="MsoNormal">
<b><br /></b></div>
<div class="MsoNormal">
<b>mongos&gt;
sh.shardCollection("myDB.pre_demo",{x:1})</b><o:p></o:p></div>
<div class="MsoNormal">
<b>mongos&gt; for(var i = 0; i &lt; 100 ; i++){<o:p></o:p></b></div>
<div class="MsoNormal">
<b>... sh.splitAt("myDB.pre_demo",{x:1000000 * i/100});<o:p></o:p></b></div>
<div class="MsoNormal">
<b>... }</b><o:p></o:p></div>
<div class="MsoNormal">
<b>mongos&gt; db.chunks.find( { ns: /demo/
},{_id:0,lastmodEpoch:0,lastmod:0})</b><o:p></o:p></div>
<div class="MsoNormal">
<i>{ "ns" : "myDB.pre_demo",
"min" : { "x" : 970000 }, "max" : { "x"
: 980000 }, "shard" : "c" }<o:p></o:p></i></div>
<div class="MsoNormal">
<i>{ "ns" : "myDB.pre_demo",
"min" : { "x" : 980000 }, "max" : { "x"
: 990000 }, "shard" : "c" }<o:p></o:p></i></div>
<div class="MsoNormal">
<i>{ "ns" : "myDB.pre_demo",
"min" : { "x" : 990000 }, "max" : { "x"
: { "$maxKey" : 1 } }, "shard" : "c" }<o:p></o:p></i></div>
<div class="MsoNormal">
<i>{ "ns" : "myDB.pre_demo",
"min" : { "x" : 10000 }, "max" : { "x"
: 20000 }, "shard" : "b" }<o:p></o:p></i></div>
<div class="MsoNormal">
<i>{ "ns" : "myDB.pre_demo",
"min" : { "x" : 20000 }, "max" : { "x"
: 30000 }, "shard" : "d" }<o:p></o:p></i></div>
<div class="MsoNormal">
<i>{ "ns" : "myDB.pre_demo",
"min" : { "x" : 30000 }, "max" : { "x"
: 40000 }, "shard" : "d" }<o:p></o:p></i></div>
<div class="MsoNormal">
<i>{ "ns" : "myDB.pre_demo",
"min" : { "x" : 40000 }, "max" : { "x"
: 50000 }, "shard" : "b" }<o:p></o:p></i></div>
<div class="MsoNormal">
<i>{ "ns" : "myDB.pre_demo",
"min" : { "x" : 50000 }, "max" : { "x"
: 60000 }, "shard" : "b" }<o:p></o:p></i></div>
<div class="MsoNormal">
<i>{ "ns" : "myDB.pre_demo",
"min" : { "x" : 60000 }, "max" : { "x"
: 70000 }, "shard" : "d" }<o:p></o:p></i></div>
<div class="MsoNormal">
<i>{ "ns" : "myDB.pre_demo",
"min" : { "x" : 70000 }, "max" : { "x"
: 80000 }, "shard" : "a" }<o:p></o:p></i></div>
<div class="MsoNormal">
<i>{ "ns" : "myDB.pre_demo",
"min" : { "x" : 80000 }, "max" : { "x"
: 90000 }, "shard" : "b" }<o:p></o:p></i></div>
<div class="MsoNormal">
</div>
<div class="MsoNormal">
<i>{ "ns" : "myDB.pre_demo",
"min" : { "x" : 90000 }, "max" : { "x"
: 100000 }, "shard" : "a" }<o:p></o:p></i><br />
<i><br /></i>
<i><br /></i>
<b>Shard key selection:</b><br />
<i><br /></i>
High Cardinality(no of values), low frequency(repetitive occurrence in insert),type of change non monotonically(timestamp changes monitonically)<br />
<br />
<br />
<b>Shard is a permanent operation</b><br />
<b><br /></b>
<br />
<div class="MsoListParagraphCxSpFirst" style="mso-list: l0 level1 lfo1; text-indent: -.25in;">
<!--[if !supportLists]--><span style="color: #424950; font-family: &quot;symbol&quot;; font-size: 12.0pt; line-height: 107%;">·<span style="font-family: &quot;times new roman&quot;; font-size: 7pt; font-stretch: normal; line-height: normal;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span><!--[endif]-->You cannot unshard a collection once sharded<o:p></o:p></div>
<div class="MsoListParagraphCxSpMiddle" style="mso-list: l0 level1 lfo1; text-indent: -.25in;">
<!--[if !supportLists]--><span style="color: #424950; font-family: &quot;symbol&quot;; font-size: 12.0pt; line-height: 107%;">·<span style="font-family: &quot;times new roman&quot;; font-size: 7pt; font-stretch: normal; line-height: normal;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span><!--[endif]-->You cannot update the shard key of a sharded
collection<o:p></o:p></div>
<br />
<div class="MsoListParagraphCxSpLast" style="mso-list: l0 level1 lfo1; text-indent: -.25in;">
<!--[if !supportLists]--><span style="color: #424950; font-family: &quot;symbol&quot;; font-size: 12.0pt; line-height: 107%;">·<span style="font-family: &quot;times new roman&quot;; font-size: 7pt; font-stretch: normal; line-height: normal;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span><!--[endif]-->You cannot update the values of the shard key
for any document in the sharded collection<o:p></o:p></div>
<div class="MsoListParagraphCxSpLast" style="mso-list: l0 level1 lfo1; text-indent: -.25in;">
e</div>
<div class="MsoListParagraphCxSpLast" style="mso-list: l0 level1 lfo1; text-indent: -.25in;">
<br /></div>
<div class="MsoListParagraphCxSpLast" style="mso-list: l0 level1 lfo1; text-indent: -.25in;">
<br /></div>
<div class="MsoListParagraphCxSpLast" style="mso-list: l0 level1 lfo1; text-indent: -.25in;">
<br /></div>
<div class="MsoListParagraphCxSpLast" style="mso-list: l0 level1 lfo1; text-indent: -.25in;">
<br /></div>
</div>
<h3 style="text-align: left;">
<i>Tips &amp; Best Practices</i></h3>
<br />
•<span style="white-space: pre;"> </span> Only shard big collections<br />
•<span style="white-space: pre;"> </span>Pick shard keys carefully<br />
•<span style="white-space: pre;"> </span>Consider pre splitting on bulk load<br />
•<span style="white-space: pre;"> </span>Be aware of monotonically increasing shard key values on inserts<br />
•<span style="white-space: pre;"> </span>Adding new shard is online but isn’t instantaneous.<br />
•<span style="white-space: pre;"> </span>Always connect to mongos ,except for some dba work – put mongos on default port<br />
•<span style="white-space: pre;"> </span>Use logical config server names.<br />
<div>
<br /></div>
<b>Hashed Shard Key:</b> index for the shard key is hashed<br />
db.collection.createIndex({field:”hashed”})<br />
chunk size – 64mb<br />
1 MB <chunk 1="" gb="" p="">db.chunks.findOne()<br />
<br />
use config<br />
db.settings.save({_id: "chunksize", value: 2}) in MB<br />
<br />
<b>Jumbo chunks </b>– when similar docs move into particular shard<br />
Cannot move jumbo chunks, Once marked as jumbo the balancer skips these and avoids trying to move them<br />
<br />
Balancer is located in primary of config server.<br />
<br />
<b>Start the balancer:</b><br />
sh.startBalancer(timeout, interval)<br />
<b>Stop the balancer:</b><br />
sh.stopBalancer(timeout, interval)<br />
<b>Enable/disable the balancer:</b><br />
sh.setBalancerState(boolean)<br />
<br />
mongos does the query merging<br />
limit() and sort()are pushed to each shard by mongos then mergesorted<br />
skip() is applied against the merged set of results<br />
</chunk><br />
<chunk 1="" gb="" p=""><br /></chunk>
config database keeps a table of shard chunk relationship<br />
mongos keeps a cache of this relationship.scatter gather is used for query not having shard key.Thus shard key should be used in majority of queries.<br />
db.products.find({"sku" : 1000000749 }).explain() – stage : single shard<br />
<br />
db.products.find( {<br />
&nbsp; "name" : "Gods And Heroes: Rome Rising - Windows [Digital Download]" }<br />
<chunk 1="" gb="" p=""></chunk><br />
).explain() – stage : shard merge<span style="white-space: pre;"> </span><br />
<div>
<br /></div>
<div>
<h3 style="text-align: left;">
All chunk migrations use the following procedure:</h3>
<br />
* The balancer process sends the moveChunk command to the source shard.<br />
<br />
* The source starts the move with an internal moveChunk command. During the migration process, operations to the chunk route to the source shard. The source shard is responsible for incoming write operations for the chunk.<br />
<br />
* The destination shard builds any indexes required by the source that do not exist on the destination.<br />
<br />
* The destination shard begins requesting documents in the chunk and starts receiving copies of the data. See also Chunk Migration and Replication.<br />
<br />
* After receiving the final document in the chunk, the destination shard starts a synchronization process to ensure that it has the changes to the migrated documents that occurred during the migration.<br />
<br />
* When fully synchronized, the source shard connects to the config database and updates the cluster metadata with the new location for the chunk.<br />
<br />
* After the source shard completes the update of the metadata, and once there are no open cursors on the chunk, the source shard deletes its copy of the documents.<br />
<br /></div>
</div>
</div>
</div>

  </div><a class="u-url" href="/vrexploring/2019/03/29/sharding-in-mongo.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/vrexploring/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">VR Exploring</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">VR Exploring</li><li><a class="u-email" href="mailto:vrexploring@gmail.com">vrexploring@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/vemarahub"><svg class="svg-icon"><use xlink:href="/vrexploring/assets/minima-social-icons.svg#github"></use></svg> <span class="username">vemarahub</span></a></li><li><a href="https://www.twitter.com/vrexploring"><svg class="svg-icon"><use xlink:href="/vrexploring/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">vrexploring</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>A space where i share my thoughts and experiences about technology , science, life, family and everything in between.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
